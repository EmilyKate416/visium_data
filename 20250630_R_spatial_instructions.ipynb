{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make environment using r_spatial.yml in Spatial folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "micromamba create -n r_spatial -f r_spatial.yml -c conda-forge --channel-priority strict\n",
    "\n",
    "R\n",
    "\n",
    "if (!requireNamespace(\"BiocManager\", quietly = TRUE))\n",
    "    install.packages(\"BiocManager\")\n",
    "\n",
    "BiocManager::install(\"nnSVG\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#locally\n",
    "mamba activate r_spatial\n",
    "rstudio #will open rstudio locally with mounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Note reasoning for batches is in comparing_outliers.csv  \n",
    " - #0 manual processing in interactive R session on cluster \n",
    " - #1 to process each sample individually via slurm submission - avoiding as it results in different numbers of rows in count matrix of each sample which prevents merging later\n",
    " - #2 to process in bulk up to or including nnsvg step  \n",
    "\n",
    "**skip ahead to 2**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "0. To manually run the preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# #open interactive node session, in terminal connect to cluster then enter\n",
    "\n",
    "srun --pty --job-name=interactive_r --mem=32G --cpus-per-task=4 --partition=epyc --time=024:00:00 bash \n",
    "#activate r environment with\n",
    "micromambda activate r_env #or r_spatial\n",
    "#open R\n",
    "R\n",
    "Sys.setenv(PATH = paste(Sys.getenv(\"PATH\"), \"/home/lythgo02/micromamba/envs/r_env\", sep = \":\"))\n",
    "#then run the commands in 20240204_QC_final_workflow.rmd but you will need to adapt the code for the samples you want to process as logbatch mitochondrial filters and the arbitrary mitochondrial filters batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. to run by as individual samples, open ssh terminal and set of individual slurm jobs for each (using a different script for the log batch and the arbitrary batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#1.0\n",
    "\n",
    "cd /mnt/scratchc/fmlab/lythgo02/visium_data/\n",
    "for SAMPLE in SITSA3 SITSB2 SITSB4 SITSC1 SITSC3 SITSD3 SITSE4 SITSF2 SITSF4 ; \n",
    "do sbatch \n",
    "--job-name=${SAMPLE} \n",
    "--output=logs/${SAMPLE}.out \n",
    "--error=logs/${SAMPLE}.err \n",
    "--time=100:00:00 \n",
    "--mem=32G \n",
    "--cpus-per-task=8 \n",
    "--partition=epyc \n",
    "--wrap=\"Rscript single_sample_process_logmito.r ${SAMPLE}\"; \n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#1.2\n",
    "\n",
    "cd /mnt/scratchc/fmlab/lythgo02/visium_data/\n",
    "\n",
    "for SAMPLE in SITSA1 SITSA2 SITSA4 SITSB1 SITSB3 SITSC2 SITSC4 SITSD1 SITSD2 SITSD4 SITSE2 SITSG2 SITSH2 ; \n",
    " do sbatch \n",
    " --job-name=${SAMPLE} \n",
    " --output=logs/${SAMPLE}.out \n",
    " --error=logs/${SAMPLE}.err \n",
    " --time=048:00:00 \n",
    " --mem=32G \n",
    " --cpus-per-task=8 \n",
    " --partition=epyc \n",
    " --wrap=\"Rscript single_sample_processing_arbitrary.r ${SAMPLE}\"; \n",
    " done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "once they have finished running cd into the respectiv folders and run the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#1.3\n",
    "\n",
    "cd logbatch \n",
    "\n",
    "for SAMPLE in post_gettophgvSITSA3 post_gettophgvSITSB2 post_gettophgvSITSB4 post_gettophgvSITSC1 post_gettophgvSITSC3 post_gettophgvSITSD3 post_gettophgvSITSE4 post_gettophgvSITSF2 post_gettophgvSITSF4; \n",
    " do     sbatch --job-name=${SAMPLE}            \n",
    " --output=logs/${SAMPLE}.out            \n",
    " --error=logs/${SAMPLE}.err            \n",
    " --time=0100:00:00            \n",
    " --mem=32G            \n",
    " --cpus-per-task=8            \n",
    " --partition=epyc            \n",
    " --wrap=\"Rscript /mnt/scratchc/fmlab/lythgo02/visium_data/logbatch/nnsvg_logbatch.r ${SAMPLE}\"; \n",
    " done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#1.4\n",
    "\n",
    "cd into arbitrary\n",
    "\n",
    "for SAMPLE in post_gettophgvSITSA1 post_gettophgvSITSA2 post_gettophgvSITSA4 post_gettophgvSITSB1 post_gettophgvSITSB3 post_gettophgvSITSC2 post_gettophgvSITSC4 post_gettophgvSITSD1 post_gettophgvSITSD2 post_gettophgvSITSD4 post_gettophgvSITSE2 post_gettophgvSITSG2 post_gettophgvSITSH2;  \n",
    "do     \n",
    "sbatch \n",
    "--job-name=${SAMPLE}            \n",
    "--output=logs/${SAMPLE}.out            \n",
    "--error=logs/${SAMPLE}.err            \n",
    "--time=0100:00:00            \n",
    "--mem=32G            \n",
    "--cpus-per-task=8            \n",
    "--partition=epyc            \n",
    "--wrap=\"Rscript /mnt/scratchc/fmlab/lythgo02/visium_data/arbitrary/nnsvg_arbitrary.r ${SAMPLE}\";\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1.5 then pick up after running nnsvg \n",
    "#open interactive r session within micromamba r_rnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#1.5\n",
    "\n",
    "knitr::opts_chunk$set(echo = TRUE)\n",
    "library(spatialLIBD)\n",
    "library(nnSVG)\n",
    "library(SpatialExperiment)  \n",
    "library(scater)\n",
    "library(AnnotationHub)\n",
    "library(tidyverse)\n",
    "library(ggspavis)\n",
    "library(scran)\n",
    "library(DT)\n",
    "projDir = \"/mnt/scratchc/fmlab/lythgo02/visium_data/\"\n",
    "\n",
    "\n",
    "load_all_data <- \"/mnt/scratchc/fmlab/lythgo02/visium_data/logbatch/nnsvg\"\n",
    "# List files in the directory\n",
    "files <- list.files(path = load_all_data, pattern = \"^nnsvg\", full.names = TRUE)\n",
    "\n",
    "# Print out the list of files\n",
    "print(files)\n",
    "\n",
    "#assign names so they are loaded into the spe with the correct identifiers\n",
    "logbatch <- c(\"SITSA3\", \"SITSB2\", \"SITSB4\", \n",
    "                 \"SITSC1\",\"SITSC3\",\"SITSD3\",\n",
    "                 \"SITSE4\",\"SITSF2\", \"SITSF4\")\n",
    "\n",
    "names(files) <- logbatch\n",
    "# Initialize a list to store each sample\n",
    "spe_list <- list()\n",
    "\n",
    "# Loop through each file and process it\n",
    "for (sample_name in names(files)) {\n",
    "  # Read the Visium data\n",
    "  spe <- readRDS(files[sample_name])\n",
    "    # Add unique barcodes\n",
    "  spe$barcode <- rownames(colData(spe))\n",
    "  spe$barcodeid <- gsub(\"-1$\", paste0(\"-\", sample_name), spe$barcode)\n",
    "  rownames(colData(spe)) <- spe$barcodeid\n",
    "  spe$sample_id <- sample_name\n",
    "\n",
    "  colData(spe)$qc_mito <- colData(spe)$log_is_outlier_mad\n",
    "  colData(spe) <- colData(spe)[ , !(colnames(colData(spe)) %in% c(\"log_mito_percent\",\"log_median_mito_percent\",\"log_mad_mito_percent\",\"log_deviation_above_median\",\"log_is_outlier_mad\"))]\n",
    "\n",
    "  # Store the processed sample in the list\n",
    "  spe_list[[sample_name]] <- spe \n",
    "  \n",
    "  \n",
    "  assign(paste0(\"spe_\", sample_name), spe)\n",
    "  #print progress check\n",
    "  cat(\"Loaded:\", sample_name, \"\\n\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#1.6 load arbitrary batch \n",
    "\n",
    "load_all_data <- \"/mnt/scratchc/fmlab/lythgo02/visium_data/arbitrary/nnsvg\"\n",
    "# List files in the directory\n",
    "files <- list.files(path = load_all_data, pattern = \"^nnsvg\", full.names = TRUE)\n",
    "\n",
    "# Print out the list of files\n",
    "print(files)\n",
    " \n",
    "#assign names so they are loaded into the spe with the correct identifiers\n",
    "arbitrary <- c(\"SITSA1\",\"SITSA2\",\"SITSA4\", \"SITSB1\", \"SITSB3\", \n",
    "                 \"SITSC2\",\"SITSC4\",\"SITSD1\",\"SITSD2\", \"SITSD4\",\n",
    "                 \"SITSE2\",\"SITSG2\", \"SITSH2\")\n",
    "\n",
    "names(files) <- arbitrary \n",
    "\n",
    "# Loop through each file and process it\n",
    "for (sample_name in names(files)) {\n",
    " # Read the Visium data\n",
    "  spe <- readRDS(files[sample_name])\n",
    "    # Add unique barcodes\n",
    "  spe$barcode <- rownames(colData(spe))\n",
    "  spe$barcodeid <- gsub(\"-1$\", paste0(\"-\", sample_name), spe$barcode)\n",
    "  rownames(colData(spe)) <- spe$barcodeid\n",
    "  spe$sample_id <- sample_name\n",
    "  \n",
    "  # Store the processed sample in the list\n",
    "  spe_list[[sample_name]] <- spe \n",
    "  \n",
    "  \n",
    "  assign(paste0(\"spe_\", sample_name), spe)\n",
    "  #print progress check\n",
    "  cat(\"Loaded:\", sample_name, \"\\n\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#1.6 bind all into one spatial object \n",
    "\n",
    "\n",
    "    spe <- do.call(cbind, spe_list) #wont work because different row numbers # wont work if row numbers differ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. To process all samples together in a slurm submission (either up to nnsvg or inc nnsvg)\n",
    "#make sure you are updating and using the scratch scripts, there are also copies on mnt but outdated\n",
    "\n",
    "1_sample_specific_filtering_wholeworkflow.r isn't actually the whole workflow as the end is commented out so that next stages are run via 2_end....sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#2.0\n",
    "\n",
    "sbatch /mnt/scratchc/fmlab/lythgo02/visium_data/scripts/submit_spatial_scripts.sh\n",
    "\n",
    "#which is \n",
    "\n",
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --error=nnSVG.err\n",
    "#SBATCH --time=0200:00:00             \n",
    "#SBATCH --cpus-per-task=32      \n",
    "#SBATCH --mem=120G                   \n",
    "#SBATCH --partition=epyc     \n",
    "\n",
    "\n",
    "# Run the R script\n",
    "#Rscript /mnt/scratchc/fmlab/lythgo02/visium_data/scripts/1_sample_specific_filtering_wholeworkflow.r "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#there is also a script called 2_end_stage_hvg_nnsvg_singlesamplejob.r which is the end section of the workflow to submit single jobs for each sample for hvg and nnsvg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1_sample_specific_filtering_wholeworkflow.r runs the following steps:\n",
    "Workflow Summary:\n",
    "\n",
    "\n",
    " - Load Visium spatial transcriptomics data per sample.\n",
    " - Add unique barcodes to each spot for tracking\n",
    " - Combine all samples into one SpatialExperiment (SPE) object.\n",
    " - Gene Annotationvia Ensembl\n",
    " - Filter out genes with zero counts.\n",
    " - Spot Filtering and QC:\n",
    "    -  Keep only spots overlaying tissue.\n",
    " - Calculate per-spot QC metrics:\n",
    "     - Number of detected genes,\n",
    "     - Total UMIs (library size),\n",
    "     - Percentage of mitochondrial UMIs.\n",
    " - Generate QC summary tables and save intermediate results.\n",
    " - Split cohort into log and arbitrary:\n",
    "     - A few of he samples have high mito content so arbitrary threshold across all doesn't work, if we expect some mitochondrial content due to systematic/technical processes then we would expect this to show up fairly uniformly across samples. For these samples I apply a sample specific threshold. Exclude spots that are more than a particular standard deviation away from the mean. \n",
    "     - Mitochondrial % filter:\n",
    "        -  In the “log” cohort, uses a sample-specific, robust outlier detection method on the log-transformed mitochondrial percentages (median ± MAD).\n",
    "        -  In the “arbitrary” cohort, applies a fixed, arbitrary threshold (e.g., >20%).\n",
    "    -  Library size and gene detection filters: use fixed thresholds for all samples regardless of cohort.\n",
    "         - Library Size QC: Apply a threshold (e.g., <300 UMIs) to flag low-quality spots.\n",
    "          -  Gene Detection QC: threshold (e.g., <300 detected genes) to flag poor spots.\n",
    " - Save QC-filtered SPE objects and plots at:\n",
    "  - visium_data/single_sample_from_filtering/20250321_spe_sub_sampleID.rds\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# 2.1 then process each sample separately for hvg and nnsvg via slurm job using following script (has the following steps in 2_end_stage_hvg_nnsvg_singlesamplejob.r)\n",
    "\n",
    "# note after separating out individual samples, SITSA1 and SITSD3 have rows with 0 count (causing nnsvg to fail) for:\n",
    "#SITSA1 - HNRNPCL3, TMOD4, REG1A USP17L10, PVRIG CNTNAP3B, ZP1, C13orf46 ZP2, PAGE2, TGIF2LY, PCDH11Y \n",
    "#SITSD3 - HNRNPCL3, PRAMEF33, UBE2U, CA14 AL590560.2, WDR64, SPDYA, NMS, ZDHHC19, USP17L10, HTN3, PCBD2, HIST1H4E, PVRIG \n",
    "         #ASZ1, AKR1C4, OOSP1, ZP1, DEFB131B, C13orf46, GOLGA6L6, TEPP, ALOX15, ANKRD30B, ZNF541, BPIFB2, BPIFB6, BPIFB3 \n",
    "         #USP41, CRYBB2, GAGE1, PAGE2, SLC25A5, TGIF2LY, PRKY \n",
    "#so the following is run again within the script\n",
    "\n",
    "# remove zero expression genes\n",
    "ix_zero_genes <- rowSums(counts(spe_SITSD3)) == 0\n",
    "table(ix_zero_genes)\n",
    "\n",
    "# identify genes with 0 expression\n",
    "true <- ix_zero_genes[ix_zero_genes]\n",
    "\n",
    "if (sum(ix_zero_genes) > 0) {\n",
    "  spe_SITSD3 <- spe_SITSD3[!ix_zero_genes, ]}\n",
    "\n",
    "# remove spots with zero expression\n",
    "ix_zero_spots <- colSums(counts(spe_SITSA1)) == 0\n",
    "table(ix_zero_spots) #0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#2.1 \n",
    "#make sure you change which line is commented out in submit_spatial_scripts.sh so 2_end_stage_hvg_nnsvg_singlesamplejob.r is submitted\n",
    "\n",
    "for sample in SITSA1 SITSA2 SITSA3 SITSA4 SITSB1 SITSB2 SITSB3 SITSB4 SITSC1 SITSC2 SITSC3 SITSC4 SITSD1 SITSD2 SITSD3 SITSD4 SITSE2 SITSE4 SITSF2 SITSF4 SITSG2 SITSH2; \n",
    "do     sbatch ../scripts/submit_spatial_scripts.sh $sample; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2_end_stage_hvg_nnsvg_singlesamplejob.r:  \n",
    " - Loads the sample-specific RDS file.  \n",
    " - Removes genes and spots with zero expression.  \n",
    " - Applies a gene filter function (filter_genes) without mitochondrial filtering.  \n",
    " - Normalizes counts and computes library size factors.  \n",
    " - Identifies highly variable genes (HVGs) using modelGeneVar and flags them. Saves intermediate data objects.  \n",
    " - Checks for normalized log-counts, then runs the nnSVG spatial gene variability method.  \n",
    " - Saves the final object with nnSVG results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 then open interactive R session and proceed as follows (skip)\n",
    "We will take the top ranking HVGs and top ranking SVGs, reduce the dimensions with PCA on each and compare  \n",
    " - runPCA() and runUMAP() from Seurat, by default calculates the top 20 PCs\n",
    " - Note results of comparing top HVGs and top SVGs are detailed below, for majority of samples top HVGs are contained within SVGs so use these for clustering and GO analysis \n",
    " - Therefore skip HVG section below and go to section 2.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#2.3 fitting top HVGs\n",
    "\n",
    "#knitr::opts_chunk$set(echo = TRUE)\n",
    "library(spatialLIBD)\n",
    "library(nnSVG)\n",
    "library(SpatialExperiment)  \n",
    "library(scater)\n",
    "library(AnnotationHub)\n",
    "library(tidyverse)\n",
    "library(ggspavis)\n",
    "library(scran)\n",
    "library(DT)\n",
    "library(HDF5Array)\n",
    "projDir = \"/mnt/scratchc/fmlab/lythgo02/visium_data/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Pre-processed Samples:  \n",
    "List files in a directory matching \"spe_sub_modelgenevar\" (these contain samples processed for highly variable genes, HVGs).  \n",
    "Loop through the files, load each .rds file into R, and store the loaded data into spe_list (a list of SpatialExperiment objects).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#2.3\n",
    "# ====== Load HVG-processed samples ======\n",
    "load_all_data <- \"/mnt/scratchc/fmlab/lythgo02/visium_data/single_sample_from_filtering/no_mito/\" \n",
    "# Alternative path (uncomment if needed)\n",
    "# load_all_data <- \"/mnt/nas-data/fmlab/group_folders/lythgo02/visium_data/single_sample_from_filtering/intermediate_results\" \n",
    "\n",
    "# Sample IDs\n",
    "samplesheet <- c(\"SITSA1\", \"SITSA2\", \"SITSA3\", \"SITSA4\",\n",
    "                 \"SITSB1\", \"SITSB2\", \"SITSB3\", \"SITSB4\", \n",
    "                 \"SITSC1\", \"SITSC2\", \"SITSC3\", \"SITSC4\", \n",
    "                 \"SITSD1\", \"SITSD2\", \"SITSD3\", \"SITSD4\",\n",
    "                 \"SITSE2\", \"SITSE4\", \"SITSF2\", \"SITSF4\",\n",
    "                 \"SITSG2\", \"SITSH2\")  \n",
    "\n",
    "# Load HVG-filtered RDS files\n",
    "hvg_files <- list.files(path = load_all_data, pattern = \"spe_sub_modelgenevar\", full.names = TRUE)\n",
    "names(hvg_files) <- samplesheet\n",
    "\n",
    "# Load HVG objects into a list\n",
    "spe_list <- list()\n",
    "for (sample_name in names(hvg_files)) {\n",
    "  spe <- readRDS(hvg_files[[sample_name]])\n",
    "  spe_list[[sample_name]] <- spe\n",
    "  cat(\"Loaded HVG sample:\", sample_name, \"\\n\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensionality reduction on top HVGs  \n",
    "Top HVGs have been determined using getTopHVGs() from scran which returns top 10% (prop=0.1) of genes with highest biological variance after discarding those with bio <= 0  \n",
    "Extract HVGs and Run PCA & UMAP (on PCAs) and save back to list  \n",
    "  \n",
    "Use PCA to reduce the dimensions of our dataset to assist clustering and UMAP to further reduce the principal components (PCs) in a two-dimensional space and produce better visualisations for the PCA.  \n",
    "runPCA() function runs PCA on a SCE object, and returns an updated version of the single cell object with the PCA result added to the reducedDim slot.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#2.3\n",
    "# ====== Extract HVGs and run PCA/UMAP ======\n",
    "set.seed(123)\n",
    "\n",
    "# Store HVG gene symbols\n",
    "hvg <- list()\n",
    "for (sample_name in names(spe_list)) {\n",
    "  hvg[[sample_name]] <- rowData(spe_list[[sample_name]]) %>%\n",
    "    as.data.frame() %>%\n",
    "    filter(hvg == TRUE) %>%\n",
    "    pull(symbol)\n",
    "\n",
    "  # PCA\n",
    "  spe_list[[sample_name]] <- runPCA(spe_list[[sample_name]], subset_row = hvg[[sample_name]], name = \"PCA_hvg\")\n",
    "}\n",
    "\n",
    "# Run UMAP on top PCs\n",
    "set.seed(987)\n",
    "for (sample_name in names(spe_list)) {\n",
    "  spe_list[[sample_name]] <- runUMAP(spe_list[[sample_name]], dimred = \"PCA_hvg\", name = \"UMAP_hvg\")\n",
    "  colnames(reducedDim(spe_list[[sample_name]], \"UMAP_hvg\")) <- c(\"UMAP_hvg1\", \"UMAP_hvg2\")\n",
    "}\n",
    "\n",
    "# (Optional) Plot PCA\n",
    "plots <- list()\n",
    "for (sample_name in names(spe_list)) {\n",
    "  sample_data <- spe_list[[sample_name]]\n",
    "  pca_df <- as.data.frame(reducedDim(sample_data, \"PCA_hvg\"))\n",
    "  pca_df$layer <- colData(sample_data)$ground_truth\n",
    "\n",
    "  plots[[sample_name]] <- ggplot(pca_df, aes(x = PC1, y = PC2, colour = layer)) +\n",
    "    geom_point(size = 0.5) +\n",
    "    scale_colour_brewer(type = \"qual\") +\n",
    "    labs(title = paste(\"PCA (Sample:\", sample_name, \")\"),\n",
    "         x = \"PC1\", y = \"PC2\", colour = \"layer\") +\n",
    "    theme_classic()\n",
    "}\n",
    "\n",
    "# Define the directory where you want to save the plots\n",
    "#save_dir <- \"/mnt/scratchc/fmlab/lythgo02/visium_data/single_sample_from_filtering/no_mito/\"\n",
    "\n",
    "#for (i in seq_along(plots)) {\n",
    "  # Define the file name based on the sample_id for uniqueness, with the full path\n",
    "  #file_name <- paste0(save_dir, \"plots/plot_hvg_pca\", spe_list[[i]]$sample_id[1], \".png\")\n",
    "  \n",
    "  # Save the plot using ggsave\n",
    " # ggsave(filename = file_name, plot = plots[[i]], width = 8, height = 6)\n",
    "#}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4 Get top SVGs  - can use R markdown for this section also \n",
    "\n",
    "nnsvg  \n",
    "The results are stored in the rowData of the SpatialExperiment object. The main results of interest are:  \n",
    " - LR_stat: likelihood ratio (LR) statistics used to rank SVGs  \n",
    " - rank: rank of top SVGs according to LR statistics  \n",
    " - pval: approximate p-values  \n",
    " - padj: approximate p-values adjusted for multiple testing  \n",
    " - prop_sv: effect size defined as proportion of spatial variance  \n",
    "  \n",
    "First load each spe object after having run nnsvg on the cluster  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#2.4 \n",
    "# ====== Load nnSVG-ranked samples ======\n",
    "load_all_data <- \"/mnt/scratchc/fmlab/lythgo02/visium_data/single_sample_from_filtering/no_mito/\" \n",
    "# Alternative path (uncomment if needed)\n",
    "samplesheet <- c(\"SITSA1\", \"SITSA2\", \"SITSA3\", \"SITSA4\",\n",
    "                 \"SITSB1\", \"SITSB2\", \"SITSB3\", \"SITSB4\", \n",
    "                 \"SITSC1\", \"SITSC2\", \"SITSC3\", \"SITSC4\", \n",
    "                 \"SITSD1\", \"SITSD2\", \"SITSD3\", \"SITSD4\",\n",
    "                 \"SITSE2\", \"SITSE4\", \"SITSF2\", \"SITSF4\",\n",
    "                 \"SITSG2\", \"SITSH2\")  \n",
    "               \n",
    "                 \n",
    "svg_files <- list.files(path = load_all_data, pattern = \"spe_sub_nnSVG\", full.names = TRUE)\n",
    "names(svg_files) <- samplesheet\n",
    "\n",
    "spe_list_nnsvg <- list()\n",
    "for (sample_name in names(svg_files)) {\n",
    "  spe_svg <- readRDS(svg_files[[sample_name]])\n",
    "  spe_list_nnsvg[[sample_name]] <- spe_svg\n",
    "  cat(\"Loaded nnSVG sample:\", sample_name, \"\\n\")\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run PCA and UMAP on top SVGs  \n",
    " - take top 10% SVGs per sample for input to runPCA, in the example from https://bookdown.org/sjcockell/ismb-tutorial-2023/practical-session-2.html#inter-cluster-differentially-expressed-genes-dges they use top 10% HVGs = ~@1400 genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "set.seed(456)\n",
    "\n",
    "svg <- list()\n",
    "common_genes_list <- list()\n",
    "\n",
    "for (sample_name in names(spe_list_nnsvg)) {\n",
    "  spe_svg <- spe_list_nnsvg[[sample_name]]\n",
    "  spe_hvg <- spe_list[[sample_name]]\n",
    "\n",
    "  # Compute top 10% SVGs\n",
    "  n_top <- ceiling(0.10 * nrow(spe_svg))  # 10% of genes\n",
    "  rowData(spe_svg)$svg <- rowData(spe_svg)$rank <= n_top\n",
    "\n",
    "  # Extract SVG gene IDs\n",
    "  svg[[sample_name]] <- rownames(spe_svg)[rowData(spe_svg)$svg]\n",
    "\n",
    "  # PCA and UMAP on selected SVGs\n",
    "  spe_svg <- runPCA(spe_svg, subset_row = svg[[sample_name]], name = \"PCA_svg\")\n",
    "  spe_svg <- runUMAP(spe_svg, dimred = \"PCA_svg\", name = \"UMAP_svg\")\n",
    "  colnames(reducedDim(spe_svg, \"UMAP_svg\")) <- c(\"UMAP_svg1\", \"UMAP_svg2\")\n",
    "\n",
    "  # Update object\n",
    "  spe_list_nnsvg[[sample_name]] <- spe_svg\n",
    "\n",
    "  # Find overlap with HVGs\n",
    " common_genes_list[[sample_name]] <- intersect(hvg[[sample_name]], svg[[sample_name]])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error: object 'spe_nnsvg_list' not found\n",
     "output_type": "error",
     "traceback": [
      "Error: object 'spe_nnsvg_list' not found\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for (sample in names(spe_list_nnsvg)){\n",
    "    spe <- spe_list_nnsvg[[sample]]\n",
    "    spe <- DelayedArray::realize(spe)\n",
    "    saveRDS(spe,\n",
    "    file=file.path(load_all_data, paste0(sample, \"nnsvg_pca_umap.rds\")))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#metadata table\n",
    "group_df <- data.frame(\n",
    "  sample_id = c(\n",
    "    \"SITSC1\", \"SITSD2\", \"SITSH2\", \"SITSC2\", \"SITSA3\",\n",
    "    \"SITSA1\", \"SITSD4\", \"SITSG2\", \"SITSB3\",\n",
    "    \"SITSB1\", \"SITSD1\", \"SITSA4\", \"SITSB4\", \"SITSF2\",\n",
    "    \"SITSC3\", \"SITSF4\", \"SITSE4\",\n",
    "    \"SITSB2\",\n",
    "    \"SITSD3\",\n",
    "    \"SITSC4\", \"SITSA2\", \"SITSE2\"\n",
    "  ),\n",
    "    subgroup = c(\n",
    "    rep(\"gBRCA1m-ov\", 5),\n",
    "    rep(\"gBRCA2m-ov\", 4),\n",
    "    rep(\"HRP-ov\", 5),\n",
    "    rep(\"non-BRCA-HRD-ov\", 3),\n",
    "    \"gBRCA2m-om\",\n",
    "    \"gBRCA1m-om\",\n",
    "    rep(\"HRP-om\", 3)\n",
    "  )\n",
    ")\n",
    "\n",
    "group_df$genotype <- sub(\"-o.*\", \"\", group_df$subgroup)\n",
    "\n",
    "\n",
    "gene_summary <- data.frame(\n",
    "  sample_id=group_df$sample_id,\n",
    "  subgroup=group_df$subgroup,\n",
    "  hvg_n=sapply(group_df$sample_id, function(sample)\n",
    "  length(hvg[[sample]])),\n",
    "  hvg_in_svg_n=sapply(group_df$sample, function(sample)\n",
    "  length(common_genes_list[[sample]])))\n",
    "\n",
    "gene_summary$genotype <- sub(\"-o.*\", \"\", gene_summary$subgroup)\n",
    "\n",
    "gene_summary$proportion <- gene_summary$hvg_in_svg_n / gene_summary$hvg_n\n",
    "\n",
    "\n",
    "\n",
    "# Set output directory\n",
    "save_dir <- \"/mnt/scratchc/fmlab/lythgo02/visium_data/single_sample_from_filtering/no_mito/plots/\"\n",
    "write.csv(gene_summary, paste0(save_dir, \"hvg_svg_gene_summary.csv\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 1️⃣ Boxplot\n",
    "p1 <- ggplot(gene_summary, aes(x = genotype, y = proportion, fill = genotype)) +\n",
    "  geom_boxplot(outlier.shape = NA, alpha = 0.5) +\n",
    "  geom_jitter(width = 0.2, size = 2) +\n",
    "  labs(\n",
    "    title = \"Proportion of HVGs also found in SVGs\",\n",
    "    x = \"Genotype\",\n",
    "    y = \"Proportion HVGs in SVGs\"\n",
    "  ) +\n",
    "  theme_minimal(base_size = 14) +\n",
    "  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n",
    "  scale_fill_brewer(palette = \"Set2\")\n",
    "\n",
    "# Save boxplot\n",
    "ggsave(filename = file.path(save_dir, \"hvg_svg_proportion_boxplot.png\"), plot = p1, width = 8, height = 6)\n",
    "\n",
    "# 2️⃣ Per-sample line plot\n",
    "p2 <- ggplot(gene_summary, aes(x = reorder(sample_id, proportion), y = proportion, color = genotype)) +\n",
    "  geom_point(size = 3) +\n",
    "  geom_segment(aes(xend = reorder(sample_id, proportion), y = 0, yend = proportion), alpha = 0.4) +\n",
    "  labs(\n",
    "    title = \"Per-sample HVG-SVG Proportion\",\n",
    "    x = \"Sample ID\",\n",
    "    y = \"Proportion\"\n",
    "  ) +\n",
    "  theme_minimal(base_size = 13) +\n",
    "  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +\n",
    "  scale_color_brewer(palette = \"Set2\")\n",
    "\n",
    "# Save per-sample plot\n",
    "ggsave(filename = file.path(save_dir, \"hvg_svg_proportion_by_sample.png\"), plot = p2, width = 10, height = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "Gene variability:\n",
    " - HVGs = Highly Variable Genes: These are genes showing high variation across spots/samples.\n",
    " - SVGs = Spatially Variable Genes: Genes whose expression varies with spatial location (spots).\n",
    " - Overlap (hvg_in_svg_n): Number of HVGs that are also spatially variable in that sample.\n",
    "\n",
    "Biological / Analytical insights:\n",
    " - High Proportion (~0.7-1.0): Most HVGs in these samples are spatially variable, implying that gene variability is largely driven by spatial differences in tissue.\n",
    " - Example: SITSA1 has a perfect 1.0 proportion — all its HVGs are spatially variable.\n",
    " - This suggests spatial patterns strongly influence gene variability here.\n",
    " - Lower Proportion (~0.45-0.6): A lower fraction of HVGs are spatially variable.\n",
    " - Example: SITSD4 with 0.45 proportion means more than half HVGs are variable but not necessarily spatially patterned — possibly due to cell type variation or technical noise.\n",
    " - Inter-sample variability: The proportion varies between samples, which might reflect biological differences (e.g., different tissue regions, pathological states) or technical differences (e.g., sequencing depth).\n",
    "\n",
    "SVGs capture genes whose expression varies spatially, which can reveal tissue structure and microenvironment = primary focus so focussing on these (esp given that for most samples >70% HVGs are in SVGs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Integrate SVGs and HVGs (or just take the SVGs if the HVGs are in SVGs for each sample)........  \n",
    "I looked into the following statement/paper and it doesn't actually seem to comment on SVG/HVG integration  \n",
    "A recent benchmark paper (Li et al. 2022) showed that integrating HVGs and SVGs to generate a combined set of features can improve downstream clustering performance in STx data. This confirms that SVGs contain additional biologically relevant information that is not captured by HVGs in these datasets. For example, a simple way to combine these features is to concatenate columns of principal components (PCs) calculated on the set of HVGs and the set of SVGs (excluding overlapping HVGs), and then using the combined set of features for further downstream analyses (Li et al. 2022)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster gene expression via scRNAseq methods:\n",
    " - Graph-based clustering using the Walktrap method implemented in scran (Lun, McCarthy, and Marioni 2016), builds shared nearest neighbour (SNN) using top 50 PCs calculated on the set of top SVGs.\n",
    " - Assume that biologically informative spatial distribution patterns of cell types can be detected from the molecular features (gene expression).\n",
    " - The chunk below clusters without taking into account xy coordinates (may be better at picking up niche relationships but trying with the spatial info accounted for initially using chunk after this)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "set.seed(123)\n",
    "cluster_summary <- list()\n",
    "\n",
    "for (sample in names(spe_list_nnsvg)) {\n",
    "  sce <- spe_list_nnsvg[[sample]]\n",
    "\n",
    "  # Build SNN using PCs from nnSVG\n",
    "  g <- scran::buildSNNGraph(\n",
    "    sce,\n",
    "    k = 35,\n",
    "    use.dimred = \"PCA_svg\",\n",
    "    type = \"jaccard\"\n",
    "  )\n",
    "  # Adjust resolution for granularity (lower = fewer clusters)\n",
    "  res <- if (ncol(sce) < 1500) 0.35 else 0.5\n",
    "\n",
    "    # --- Sample-specific overrides ---\n",
    "  if (sample %in% c(\"SITSA1\",\"SITSB2\", \"SITSC3\", \"SITSC1\", \"SITSC4\", \"SITSE4\", \"SITSD4\", \"SITSH2\")) {\n",
    "    res <- 0.35\n",
    "  }\n",
    "  if (sample %in% c(\"SITSA4\", \"SITSC2\")) {\n",
    "    res <- 0.3\n",
    "  }\n",
    "\n",
    "  # Leiden clustering\n",
    "  g_leiden <- igraph::cluster_leiden(\n",
    "    g,\n",
    "    objective_function   = \"modularity\",     # or \"CPM\" for finer structure\n",
    "    weights              = igraph::E(g)$weight,\n",
    "    resolution_parameter = res,\n",
    "    n_iterations         = -1\n",
    "  )\n",
    "  clus <- g_leiden$membership\n",
    "  # Store cluster labels and summaries\n",
    "  colLabels(sce) <- factor(clus)\n",
    "  cluster_summary[[sample]] <- table(clus)\n",
    "  spe_list_nnsvg[[sample]] <- sce\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The approach described in the tutorial then suggests adding the raw (or normalized) x-y spatial coordinates as additional dimensions during clustering — concatenated with SVG PCAs \n",
    "This directly and explicitly forces the clustering to also consider physical proximity in space.\n",
    "\n",
    "The following section combines PCAs and xy-coordinates as a slot in the spatial experiment named \"PCA_svg_plus_xy\"  \n",
    "NOT DOING THIS because the cluster n that results are too high and granular "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#For example:\n",
    "\n",
    "# Combine PCA of SVGs + spatial coordinates\n",
    "#spot_counts <- sapply(spe_list_nnsvg, ncol)\n",
    "#spot_counts_df <- data.frame(spot_counts, \n",
    "                             guide_k = ifelse(spot_counts>2000,15,10)) # if spot number >2000 k = 15, otherwise k=10\n",
    "\n",
    "\n",
    "#for (sample in names(spe_list_nnsvg)) {\n",
    "#  spe <- spe_list_nnsvg[[sample]]  # extract sample object\n",
    "  # Extract PCA\n",
    "#  pcs <- reducedDim(spe, \"PCA_svg\")\n",
    "  # Extract and relabel coords to match colnames (with sample ID)\n",
    "#  coords <- spatialCoords(spe)\n",
    "#  rownames(coords) <- paste0(sub(\"-1$\", \"\", rownames(coords)), \"-\", sample)\n",
    "  # Sanity check: ensure rownames match\n",
    "#  stopifnot(identical(rownames(pcs), rownames(coords)))\n",
    "  # Combine PCA + spatial coordinates\n",
    "#  combined <- cbind(pcs, coords)\n",
    "#  reducedDim(spe, \"PCA_svg_plus_xy\") <- combined\n",
    "  # Set k from spot_counts_df (ensure rownames are correct)\n",
    "#  k_value <- spot_counts_df[sample, \"guide_k\"]\n",
    "  # Build SNN graph using reducedDim\n",
    "#  g <- buildSNNGraph(spe, k = 15, use.dimred = \"PCA_svg_plus_xy\")\n",
    "  # Apply Walktrap clustering\n",
    "#  g_walk <- igraph::cluster_walktrap(g)\n",
    "#  clus <- g_walk$membership\n",
    "  # Assign clusters\n",
    "#  colLabels(spe) <- factor(clus)\n",
    "  # Save updated object back into list\n",
    "#  spe_list_nnsvg[[sample]] <- spe\n",
    "#}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "save_dir <- \"/mnt/scratchc/fmlab/lythgo02/visium_data/single_sample_from_filtering/no_mito/\"\n",
    "#for each sample, count how many unique clusters were found\n",
    "cluster_counts <- data.frame(\n",
    "  sample_id = names(spe_list_nnsvg),\n",
    "  n_clusters = sapply(spe_list_nnsvg, function(s) length(unique(colLabels(s)))),\n",
    "  n_spots=sapply(spe_list_nnsvg, ncol)\n",
    ")\n",
    "cluster_counts\n",
    "#add meta data\n",
    "cluster_counts$subgroup <- group_df$subgroup[match(cluster_counts$sample_id, group_df$sample_id)]\n",
    "cluster_counts$genotype <- sub(\"-o.*\", \"\", cluster_counts$subgroup)\n",
    "\n",
    "write.csv(cluster_counts, paste0(save_dir, \"cluster_counts.csv\"), row.names = FALSE)\n",
    "\n",
    "library(ggplot2)\n",
    "#plot cluster number per sample, coloured by genotype\n",
    "p3 <-ggplot(cluster_counts, aes(x = reorder(sample_id, n_clusters), y = n_clusters, color = genotype)) +\n",
    "  geom_point(size = 3) +\n",
    "  geom_segment(aes(xend = reorder(sample_id, n_clusters), y = 0, yend = n_clusters), alpha = 0.4) +\n",
    "  labs(\n",
    "    title = \"Per-sample Cluster Diversity\",\n",
    "    x = \"Sample ID\",\n",
    "    y = \"Number of Clusters\"\n",
    "  ) +\n",
    "  theme_minimal(base_size = 13) +\n",
    "  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +\n",
    "  scale_color_brewer(palette = \"Set2\")\n",
    "\n",
    "p4 <- ggplot(cluster_counts, aes(x = n_spots, y = n_clusters, color = subgroup, label = sample_id)) +\n",
    "  geom_point(size = 3) +\n",
    "  geom_text(vjust = -0.8, size = 3) +\n",
    "  theme_minimal() +\n",
    "  labs(\n",
    "    title = \"Number of clusters vs number of spots per sample\",\n",
    "    x = \"Number of spots\",\n",
    "    y = \"Number of clusters\"\n",
    "  ) +\n",
    "  theme(plot.title = element_text(face = \"bold\", hjust = 0.5))\n",
    "\n",
    "ggsave(filename = file.path(save_dir, \"spatial_clusters.png\"), plot = p3, width = 10, height = 6)\n",
    "ggsave(filename = file.path(save_dir, \"spotsvsclusters.png\"), plot = p4, width = 10, height = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot spatial domains  \n",
    "Plot PCA coloured by spatial domain label  \n",
    "Plot UMAP coloured by spatial domain label  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "results <- \"/mnt/scratchc/fmlab/lythgo02/visium_data/single_sample_from_filtering/no_mito/\"\n",
    "\n",
    "spe_list_nnsvg <- readRDS(file.path(results, \"spe_list_nnsvg_clusters.rds\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "for (sample in names(spe_list_nnsvg)) {\n",
    "  spe <- spe_list_nnsvg[[sample]]\n",
    "  plotSpots(spe, annotate = \"label\")\n",
    "  ggsave(filename =  file.path(save_dir, paste0(sample, \"_SVGs_clustered.png\")), width = 6, height = 6)\n",
    "  plotDimRed(spe, plot_type=\"UMAP_svg\", annotate=\"label\")\n",
    "  ggsave(filename =  file.path(save_dir, paste0(sample, \"_umap.png\")), width = 6, height = 6)\n",
    "  #plotDimRed(spe, plot_type=\"PCA_svg\", annotate=\"label\")\n",
    "  #ggsave(filename =  file.path(save_dir, paste0(sample, \"_pca.png\")), width = 6, height = 6)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps\n",
    "Differential Expression Between Clusters\n",
    "Gene Ontology / Pathway Enrichment\n",
    "\n",
    "Engineer towards Aim 2: Characterize gene expression programs underpinning immune cell states\n",
    "•\tIdentify transcriptional programs (e.g., exhaustion, cytotoxicity, IFN response, chemokine signaling) that define functional immune states and differ by genomic subtype.\n",
    "o\tFocus: Cell-intrinsic functional states and pathway enrichment\n",
    "o\tBRCA1 tumours → high IFN/CXCL9/10 → exhausted T cells; BRCA2 → less IFN but more NK cell infiltration. Diversity amongst non BRCA HRD and HRP which is yet to be defined.\n",
    "o\tGoal: Link T, NK and tumour cell behaviors and pathways to genomic context \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform gene ontology enrichment abnalysis on cluster-specific DGEs:  \n",
    "For each sample, and each cluster within the sample, perform:  \n",
    "    Differential expression (cluster vs all others)  \n",
    "    Select DEGs (FDR < 0.05)  \n",
    "    Map gene symbols → Entrez IDs  \n",
    "    Run GO enrichment analysis (Biological Process category)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#2.5 \n",
    "# ====== Load clusstering results ======\n",
    "load_all_data <- \"/mnt/scratchc/fmlab/lythgo02/visium_data/single_sample_from_filtering/no_mito/\" \n",
    "# Alternative path (uncomment if needed)\n",
    "samplesheet <- c(\"SITSA1\", \"SITSA2\", \"SITSA3\", \"SITSA4\",\n",
    "                 \"SITSB1\", \"SITSB2\", \"SITSB3\", \"SITSB4\", \n",
    "                 \"SITSC1\", \"SITSC2\", \"SITSC3\", \"SITSC4\", \n",
    "                 \"SITSD1\", \"SITSD2\", \"SITSD3\", \"SITSD4\",\n",
    "                 \"SITSE2\", \"SITSE4\", \"SITSF2\", \"SITSF4\",\n",
    "                 \"SITSG2\", \"SITSH2\")  \n",
    "                 \n",
    "svg_files <- list.files(path = load_all_data, pattern = \"nnsvg_pca_umap.rds\", full.names = TRUE)\n",
    "names(svg_files) <- samplesheet\n",
    "\n",
    "spe_list_nnsvg <- list()\n",
    "for (sample_name in names(svg_files)) {\n",
    "  spe_svg <- readRDS(svg_files[[sample_name]])\n",
    "  spe_list_nnsvg[[sample_name]] <- spe_svg\n",
    "  cat(\"Loaded nnSVG sample:\", sample_name, \"\\n\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "results <- \"/mnt/scratchc/fmlab/lythgo02/visium_data/single_sample_from_filtering/no_mito/\"\n",
    "\n",
    "spe_list_nnsvg <- readRDS(file.path(results, \"spe_list_nnsvg_clusters.rds\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract gene list per cluster for each sample and find DE genes between clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(clusterProfiler)\n",
    "library(org.Hs.eg.db)\n",
    "library(scater)\n",
    "\n",
    "\n",
    "de_results_list <- list()\n",
    "\n",
    "for (sample in names(spe_list_nnsvg)) {\n",
    "  spe <- spe_list_nnsvg[[sample]]\n",
    "  clusters <- colLabels(spe)\n",
    "\n",
    "  # DE between clusters\n",
    "  de <- findMarkers(spe, groups = clusters, test.type = \"t\",  lfc = 0.5, direction = \"up\")\n",
    "  de_results_list[[sample]] <- de \n",
    "   # ALSO save into the SCE object itself\n",
    "  metadata(spe)$de_markers <- de\n",
    "\n",
    "  # Put updated object back into the list\n",
    "  spe_list_nnsvg[[sample]] <- spe \n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "saveRDS(spe_list_nnsvg, paste0(results, \"spe_list_nnsvg_clusters_DEmarkers.rds\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load spe list with DE markers (raw unfiltered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "results <- \"/mnt/scratchc/fmlab/lythgo02/visium_data/single_sample_from_filtering/no_mito/\"\n",
    "\n",
    "spe_list_nnsvg <- readRDS(file.path(results, \"spe_list_nnsvg_clusters_DEmarkers.rds\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------\n",
    "# Extract filtered DE marker genes per cluster per sample\n",
    "# Criteria:\n",
    "#   - FDR < 0.05  (statistical significance)\n",
    "#   - summary.logFC >= 1  (minimum effect size ≈ 2-fold change)\n",
    "# -------------------------------------------------------------------------\n",
    "# Export filtered DE tables per sample with full statistics\n",
    "# -------------------------------------------------------------------------\n",
    "output_dir <- \"/mnt/scratchc/fmlab/lythgo02/visium_data/single_sample_from_filtering/no_mito/de_csv/\"\n",
    "dir.create(output_dir, showWarnings = FALSE, recursive = TRUE)\n",
    "\n",
    "for (sample in names(de_results_list)) {\n",
    "\n",
    "  de <- de_results_list[[sample]]\n",
    "\n",
    "  # Build one long dataframe per sample (stacking clusters)\n",
    "  sample_df <- dplyr::bind_rows(lapply(names(de), function(cluster_id) {\n",
    "\n",
    "    df <- as.data.frame(de[[cluster_id]])\n",
    "\n",
    "    # Apply your filtering criteria\n",
    "    keep <- df$FDR < 0.05 & df$summary.logFC >= 1\n",
    "    df <- df[keep, , drop = FALSE]\n",
    "\n",
    "    # If nothing passes, return NULL so bind_rows skips it\n",
    "    if (nrow(df) == 0) return(NULL)\n",
    "\n",
    "    # Add identifiers\n",
    "    df$gene <- rownames(df)\n",
    "    df$cluster <- cluster_id\n",
    "    df$sample <- sample\n",
    "\n",
    "    # Reorder so identifiers come first\n",
    "    df <- df[, c(\"sample\", \"cluster\", \"gene\",\n",
    "                 setdiff(colnames(df), c(\"sample\", \"cluster\", \"gene\"))),\n",
    "             drop = FALSE]\n",
    "\n",
    "    df\n",
    "  }))\n",
    "\n",
    "  # If no clusters had any passing genes, skip writing\n",
    "  if (is.null(sample_df) || nrow(sample_df) == 0) next\n",
    "\n",
    "  # Write per-sample CSV\n",
    "  write.csv(\n",
    "    sample_df,\n",
    "    file.path(output_dir, paste0(sample, \"_DE_top_hits.csv\")),\n",
    "    row.names = FALSE\n",
    "  )\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map DEGs to Entrez IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "entrez_list <- list()\n",
    "\n",
    "for (sample in names(de_results_list)) {\n",
    "  de <- de_results_list[[sample]]\n",
    "  sample_entrez <- list()\n",
    "\n",
    "  for (cluster_id in names(de)) {\n",
    "\n",
    "    top_genes <- rownames(de[[cluster_id]])[\n",
    "      de[[cluster_id]]$FDR < 0.05 & de[[cluster_id]]$summary.logFC >= 1 #filter by FDR and effect size (logFC) to reduce gene number\n",
    "    ]\n",
    "    top_genes <- unique(na.omit(top_genes))\n",
    "    if (length(top_genes) < 5) next\n",
    "\n",
    "    gene_df <- bitr(top_genes, fromType=\"SYMBOL\", toType=\"ENTREZID\", OrgDb=org.Hs.eg.db)\n",
    "    if (is.null(gene_df) || nrow(gene_df) < 5) next\n",
    "\n",
    "    entrez <- unique(na.omit(gene_df$ENTREZID))\n",
    "    if (length(entrez) < 5) next\n",
    "\n",
    "    sample_entrez[[cluster_id]] <- entrez\n",
    "  }\n",
    "\n",
    "  if (length(sample_entrez) > 0) {\n",
    "    entrez_list[[sample]] <- sample_entrez\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check degree of overlap in marker genes between clusters  \n",
    " - if multiple clusters in a sample exceed 0.6-0.8 shared DE genes between clusters then suggests over-clustered, adjust resolution and k accordingly\n",
    " - used to set sample specific resolution for clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#check overlap in DE genes distinguishing clusters\n",
    "overlap_proportion <- lapply(entrez_list, function(sample_clusters) {\n",
    "  cluster_ids <- names(sample_clusters)\n",
    "  n_clusters  <- length(cluster_ids)\n",
    "  \n",
    "  # Matrix to store pairwise overlap proportions\n",
    "  overlap_matrix <- matrix(NA, n_clusters, n_clusters,\n",
    "                           dimnames = list(cluster_ids, cluster_ids))\n",
    "  \n",
    "  for (cluster_i in cluster_ids) {\n",
    "    genes_i <- sample_clusters[[cluster_i]]\n",
    "    \n",
    "    for (cluster_j in cluster_ids) {\n",
    "      genes_j <- sample_clusters[[cluster_j]]\n",
    "      \n",
    "      shared_genes <- length(intersect(genes_i, genes_j))\n",
    "      total_genes_i <- length(genes_i)\n",
    "      \n",
    "      overlap_matrix[cluster_i, cluster_j] <- shared_genes / total_genes_i\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  overlap_matrix\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "results <- \"/mnt/scratchc/fmlab/lythgo02/visium_data/single_sample_from_filtering/no_mito/\"\n",
    "\n",
    "spe_list_nnsvg <- readRDS(file.path(results, \"spe_list_nnsvg_clusters.rds\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clusterProfiler https://pmc.ncbi.nlm.nih.gov/articles/PMC8454663/\n",
    "\n",
    "GO enrichment analysis \n",
    " - use enrichGO() from clusterProfiler() \n",
    " - Categorises genes into chosen ontology (biological processes BP) using GO consortium to give list of enriched biological processes \n",
    "\n",
    "Performs gene ontology over-representation (ORA GO) test by hypergeometric test (essentially Fisher's exact test) to test whether GO term is enriched in cluster/subgroup genes compared to background\n",
    " - GO terms are organised as a graph with edges representing a parent-child relationship, so parent terms and all of it's child terms will be returned in GO results, hence there is a lot of redundancy in the list of GO terms returned  \n",
    " - There, we run simplify() after which uses GOSemSim package to calculate semantic similarity between terms are remove redundant terms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "compare_go_list <- list()\n",
    "\n",
    "for (sample in names(entrez_list)) {\n",
    "  message(\"Running compareCluster (GO) for \", sample, \"...\")\n",
    "\n",
    "  compare_go_list[[sample]] <- compareCluster(\n",
    "    geneCluster   = entrez_list[[sample]],\n",
    "    fun           = \"enrichGO\",\n",
    "    ont           = \"BP\",\n",
    "    OrgDb         = org.Hs.eg.db,\n",
    "    pAdjustMethod = \"BH\",\n",
    "    qvalueCutoff  = 0.05\n",
    "  )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "Remove redundancy in terms using simplify() from clusterprofiler\n",
    " - amongst similar terms, it picks the most statistically significant term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "go_compare_simplified <- lapply(compare_go_list, simplify)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KEGG pathway analysis \n",
    " - Pathway based interpretation of how genes work together in molecular network using Kyoto Encyclopedia of Genes and Genomes (KEGG) curated database of pathways\n",
    " - molecular mechanisms/signalling interpretation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or run withh compareCluster  \n",
    " - calculates enrichment between clusters and aggregates into single object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "compare_kegg_list <- list()\n",
    "\n",
    "for (sample in names(entrez_list)) {\n",
    "  message(\"Running compareCluster (KEGG) for \", sample, \"...\")\n",
    "\n",
    "  compare_kegg_list[[sample]] <- compareCluster(\n",
    "    geneCluster   = entrez_list[[sample]],\n",
    "    fun           = \"enrichKEGG\",\n",
    "    organism      = \"hsa\",\n",
    "    pAdjustMethod = \"BH\",\n",
    "    qvalueCutoff  = 0.05\n",
    "  )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reactome analysis  \n",
    " - additional pathway based database (more detailed and hierarchical than KEGG)\n",
    " - human specific (unlike KEGG)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(ReactomePA)  \n",
    "\n",
    "compare_reactome_list <- list()\n",
    "for (sample in names(entrez_list)) {\n",
    "  compare_reactome_list[[sample]] <- compareCluster(\n",
    "    geneCluster   = entrez_list[[sample]],\n",
    "    fun           = \"enrichPathway\",  # qualify the function\n",
    "    organism      = \"human\",                      # NOT \"hsa\"\n",
    "    pAdjustMethod = \"BH\",\n",
    "    pvalueCutoff  = 0.05\n",
    "  ) \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSigDB analysis for Hallmark gene pathways \n",
    "MSigDB Hallmark gene sets represent a compact collection of core biological and tumour programs reflecting cellular states such as inflammation, stromal activation, proliferation, metabolism, and immune signaling.\n",
    "https://pmc.ncbi.nlm.nih.gov/articles/PMC4707969/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(msigdbr)\n",
    "library(clusterProfiler)\n",
    "library(dplyr)\n",
    "\n",
    "# MSigDB Hallmark gene sets (human)\n",
    "m_df <- msigdbr(species = \"Homo sapiens\", category = \"H\")\n",
    "\n",
    "# TERM2GENE object\n",
    "m_t2g <- m_df %>%\n",
    "  dplyr::select(gs_name, entrez_gene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "compare_msigdb_list <- list()\n",
    "\n",
    "for (sample in names(entrez_list)) {\n",
    "  message(\"Running compareCluster (MSigDB) for \", sample, \"...\")\n",
    "\n",
    "  compare_msigdb_list[[sample]] <- compareCluster(\n",
    "    geneCluster   = entrez_list[[sample]],\n",
    "    fun           = \"enricher\",\n",
    "    TERM2GENE     = m_t2g,\n",
    "    pAdjustMethod = \"BH\",\n",
    "    qvalueCutoff  = 0.05\n",
    "  )\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "results <- \"/mnt/scratchc/fmlab/lythgo02/visium_data/single_sample_from_filtering/no_mito/\"\n",
    "#saveRDS(kegg_results_list, paste0(results, \"kegg_results.rds\"))\n",
    "saveRDS(compare_kegg_list, paste0(results, \"kegg_clustercompare_results.rds\"))\n",
    "saveRDS(go_compare_simplified, paste0(results, \"clustercompare_go_results_simplified.rds\"))\n",
    "saveRDS(compare_reactome_list, paste0(results, \"reactome_comparecluster_results.rds\"))\n",
    "saveRDS(spe_list_nnsvg, paste0(results, \"spe_list_nnsvg_clusters.rds\"))\n",
    "saveRDS(compare_msigdb_list, paste0(results, \"msigdb_comparecluster_results.rds\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "Subgroup comparison to try and narrow the scope of investigations into cluster heterogeneity \n",
    " - pool DE genes (from clusters) per subgroup, take genes that are consistently DE (>= 2 samples) and perform enrichment analyses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "immune_lookup <- tribble(\n",
    "  ~sits_id, ~immune_cat,\n",
    "  \"SITSB2\", \"Effector dominant\",\n",
    "  \"SITSA4\", \"Macrophage dominant\",\n",
    "  \"SITSB1\", \"Effector dominant\",\n",
    "  \"SITSC1\", \"Immune Desert\",\n",
    "  \"SITSB4\", \"Immune Desert\",\n",
    "  \"SITSA3\", \"Macrophage dominant\",\n",
    "  \"SITSD4\", \"Immune Desert\",\n",
    "  \"SITSA2\", \"Immune Desert\",\n",
    "  \"SITSC2\", \"Effector dominant\",\n",
    "  \"SITSD3\", \"Effector dominant\",\n",
    "  \"SITSG2\", \"Macrophage dominant\",\n",
    "  \"SITSD2\", \"Macrophage dominant\",\n",
    "  \"SITSH2\", \"Macrophage dominant\",\n",
    "  \"SITSE4\", \"Immune Desert\",\n",
    "  \"SITSC3\", \"Macrophage dominant\",\n",
    "  \"SITSF4\", \"Macrophage dominant\",\n",
    "  \"SITSE2\", \"Effector dominant\",\n",
    "  \"SITSF2\", \"Immune Desert\",\n",
    "  \"SITSA1\", \"Immune Desert\",\n",
    "  \"SITSB3\", \"Immune Desert\",\n",
    "  \"SITSC4\", \"Immune Desert\",\n",
    "  \"SITSD1\", \"Immune Desert\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pool genes per subgroup, two options:\n",
    " - chunk directly below pools genes and then applies a filter so that only genes present in > 30% samples (in the subgroup) are kept \n",
    " - chunk that follows (in use) just takes all genes and counts each gene only once (regardless of number of clusters or samples the gene is found in)\n",
    "There are various arguments for whihc way to do it but each has it's own biases and it's ok if aware of limitations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#genes_per_subgroup <- list()\n",
    "\n",
    "#min_prop <- 0.30  # adjust to 0.4 if you want stricter\n",
    "\n",
    "#for (subgrp in unique(immune_lookup$immune_cat)) {\n",
    "\n",
    " # samples <- immune_lookup$sits_id[immune_lookup$immune_cat == subgrp]\n",
    " # n_samp  <- length(samples)\n",
    " # min_n   <- max(2, ceiling(min_prop * n_samp))  # size-controlled threshold\n",
    "\n",
    "  # collect genes per sample (unique within sample)\n",
    "  #sample_genes <- lapply(samples, function(s) {\n",
    "  #  if (!is.null(entrez_list[[s]])) unique(unlist(entrez_list[[s]])) else character(0)\n",
    "  #})\n",
    "\n",
    "  # prevalence across samples (each sample contributes 0/1 per gene)\n",
    "  #gene_counts <- table(unlist(sample_genes))\n",
    "\n",
    "  #genes_per_subgroup[[subgrp]] <- names(gene_counts[gene_counts >= min_n])\n",
    "#}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#    (keep genes present in >=1 samples)  gives same result as present in >= 2 samples \n",
    "# -----------------------------\n",
    "genes_per_subgroup <- list()\n",
    "\n",
    "for (subgrp in unique(immune_lookup$immune_cat)) {\n",
    "\n",
    "  samples <- immune_lookup$sits_id[immune_lookup$immune_cat == subgrp]\n",
    "\n",
    "  # collect genes per sample (skip NULLs)\n",
    "  sample_genes <- lapply(samples, function(s) {\n",
    "    if (!is.null(entrez_list[[s]])) unlist(entrez_list[[s]]) else character(0)\n",
    "  })\n",
    "\n",
    "  # IMPORTANT: count presence across samples (not total occurrences)\n",
    "  gene_counts <- table(unlist(lapply(sample_genes, unique)))\n",
    "\n",
    "  genes_per_subgroup[[subgrp]] <- names(gene_counts[gene_counts >= 1])\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ORA per subgroup - hallmark pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# 2) ORA per subgroup + save CSV\n",
    "# -----------------------------\n",
    "ora_subgroup_results <- list()\n",
    "\n",
    "for (subgrp in names(genes_per_subgroup)) {\n",
    "\n",
    "  message(\"Running ORA for subgroup: \", subgrp)\n",
    "\n",
    "  pooled_genes <- genes_per_subgroup[[subgrp]]\n",
    "\n",
    "  if (length(pooled_genes) < 10) {\n",
    "    message(\"Skipping \", subgrp, \" (too few genes: \", length(pooled_genes), \")\")\n",
    "    next\n",
    "  }\n",
    "\n",
    "  res <- enricher(\n",
    "    gene          = pooled_genes,\n",
    "    TERM2GENE     = m_t2g,\n",
    "    pAdjustMethod = \"BH\",\n",
    "    pvalueCutoff  = 0.05,\n",
    "    minGSSize     = 15,\n",
    "    maxGSSize     = 500\n",
    "  )\n",
    "\n",
    "  if (is.null(res) || nrow(as.data.frame(res)) == 0) next\n",
    "\n",
    "  ora_subgroup_results[[subgrp]] <- res\n",
    "\n",
    "  write.csv(\n",
    "    as.data.frame(res),\n",
    "    file = file.path(results, paste0(\"ora_subgroup_\", gsub(\" \", \"_\", subgrp), \"_msigdb_hallmark.csv\")),\n",
    "   # file = file.path(results, paste0(\"ora_subgroup_\", gsub(\" \", \"_\", subgrp), \"_msigdb_immune_C7.csv\")),\n",
    "    row.names = FALSE\n",
    "  )\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "Subgroup comparison using immune set of genes from MSigDB (C7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# MSigDB Hallmark gene sets (human)\n",
    "m_df <- msigdbr(species = \"Homo sapiens\", category = \"C7\")\n",
    "\n",
    "# TERM2GENE object\n",
    "m_t2g <- m_df %>%\n",
    "  dplyr::select(gs_name, entrez_gene)\n",
    "\n",
    "  #then re-run the code chunk above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KEGG per subgroup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "ora_kegg_subgroup <- list()\n",
    "\n",
    "for (subgrp in names(genes_per_subgroup)) {\n",
    "\n",
    "  message(\"Running KEGG ORA for subgroup: \", subgrp)\n",
    "\n",
    "  pooled_entrez <- unique(na.omit(genes_per_subgroup[[subgrp]]))\n",
    "\n",
    "  if (length(pooled_entrez) < 10) {\n",
    "    message(\"Skipping \", subgrp, \" (too few genes: \", length(pooled_entrez), \")\")\n",
    "    next\n",
    "  }\n",
    "\n",
    "  res <- enrichKEGG(\n",
    "    gene          = pooled_entrez,\n",
    "    organism      = \"hsa\",\n",
    "    pAdjustMethod = \"BH\",\n",
    "    pvalueCutoff  = 0.05,\n",
    "    qvalueCutoff  = 0.05,\n",
    "    minGSSize     = 15,\n",
    "    maxGSSize     = 500\n",
    "  )\n",
    "\n",
    "  if (is.null(res) || nrow(as.data.frame(res)) == 0) next\n",
    "\n",
    "  # Optional: convert Entrez IDs in the result to readable gene symbols\n",
    "  res <- setReadable(res, OrgDb = org.Hs.eg.db, keyType = \"ENTREZID\")\n",
    "\n",
    "  ora_kegg_subgroup[[subgrp]] <- res\n",
    "\n",
    "  write.csv(\n",
    "    as.data.frame(res),\n",
    "    file = file.path(results, paste0(\"ora_subgroup_\", gsub(\" \", \"_\", subgrp), \"_KEGG.csv\")),\n",
    "    row.names = FALSE\n",
    "  )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genotype specific subgroup GO comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#or for genotype specific\n",
    "\n",
    "\n",
    "#metadata table\n",
    "group_df <- data.frame(\n",
    "  sample_id = c(\n",
    "    \"SITSC1\", \"SITSD2\", \"SITSH2\", \"SITSC2\", \"SITSA3\",\n",
    "    \"SITSA1\", \"SITSD4\", \"SITSG2\", \"SITSB3\",\n",
    "    \"SITSB1\", \"SITSD1\", \"SITSA4\", \"SITSB4\", \"SITSF2\",\n",
    "    \"SITSC3\", \"SITSF4\", \"SITSE4\",\n",
    "    \"SITSB2\",\n",
    "    \"SITSD3\",\n",
    "    \"SITSC4\", \"SITSA2\", \"SITSE2\"\n",
    "  ),\n",
    "    subgroup = c(\n",
    "    rep(\"gBRCA1m-ov\", 5),\n",
    "    rep(\"gBRCA2m-ov\", 4),\n",
    "    rep(\"HRP-ov\", 5),\n",
    "    rep(\"non-BRCA-HRD-ov\", 3),\n",
    "    \"gBRCA2m-om\",\n",
    "    \"gBRCA1m-om\",\n",
    "    rep(\"HRP-om\", 3)\n",
    "  )\n",
    ")\n",
    "\n",
    "group_df$genotype <- sub(\"-o.*\", \"\", group_df$subgroup)\n",
    "\n",
    "#get genes per subgroup\n",
    "#    (keep genes present in >=2 samples)\n",
    "# -----------------------------\n",
    "genes_per_subgroup <- list()\n",
    "\n",
    "for (subgrp in unique(group_df$genotype)) {\n",
    "\n",
    "  samples <- group_df$sample_id[group_df$genotype == subgrp]\n",
    "\n",
    "  # collect genes per sample (skip NULLs)\n",
    "  sample_genes <- lapply(samples, function(s) {\n",
    "    if (!is.null(entrez_list[[s]])) unlist(entrez_list[[s]]) else character(0)\n",
    "  })\n",
    "\n",
    "  # IMPORTANT: count presence across samples (not total occurrences)\n",
    "  gene_counts <- table(unlist(lapply(sample_genes, unique)))\n",
    "\n",
    "  genes_per_subgroup[[subgrp]] <- names(gene_counts[gene_counts >= 1])\n",
    "}\n",
    "\n",
    "names(genes_per_subgroup) <- unique(group_df$genotype)\n",
    "\n",
    "#or with size control (e.g. gene must be present in >=30% of samples in subgroup)\n",
    "\n",
    "#min_prop <- 0.30  # set to 0.40 for stricter consistency\n",
    "\n",
    "#genes_per_subgroup <- lapply(unique(group_df$genotype), function(subgrp) {\n",
    " # samples <- group_df$sample_id[group_df$genotype == subgrp]\n",
    " # n_samp  <- length(samples)\n",
    "\n",
    "  # Size-controlled minimum number of samples a gene must appear in\n",
    "  #min_n <- max(2, ceiling(min_prop * n_samp))\n",
    "\n",
    "  # Collect DE genes per sample (unique within sample)\n",
    "  #sample_genes <- lapply(samples, function(s) {\n",
    "  #  if (!is.null(entrez_list[[s]])) unique(unlist(entrez_list[[s]])) else character(0)\n",
    "  #})\n",
    "  #gene_counts <- table(unlist(sample_genes))\n",
    "  #names(gene_counts[gene_counts >= min_n])\n",
    "#})\n",
    "\n",
    "#names(genes_per_subgroup) <- unique(group_df$genotype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "go_results_subgroup <- lapply(names(genes_per_subgroup), function(subgrp) {\n",
    "  enrichGO(\n",
    "    gene = genes_per_subgroup[[subgrp]],\n",
    "    OrgDb = org.Hs.eg.db,\n",
    "    ont = \"BP\",\n",
    "    pAdjustMethod = \"BH\",\n",
    "    pvalueCutoff = 0.05,\n",
    "    readable = TRUE\n",
    "  )\n",
    "})\n",
    "\n",
    "go_results_subgroup_simplified <- lapply(go_results_subgroup, function(ego) {\n",
    "  simplify(\n",
    "    ego,\n",
    "    cutoff = 0.7,\n",
    "    by = \"p.adjust\",\n",
    "    select_fun = min\n",
    "  )\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "plots<- lapply(names(go_results_list), function(sample){\n",
    "  sample_results <- go_results_list[[sample]]\n",
    "  \n",
    "  cluster_plots <- lapply(names(sample_results), function(cluster){\n",
    "    cluster_result <- sample_results[[cluster]]\n",
    "    p <- barplot(cluster_result, showCategory=5) +\n",
    "      ggtitle(cluster)+\n",
    "      theme( axis.text.x = element_text(size = 6, angle = 45, hjust = 1),  # smaller and rotated x-axis labels\n",
    "        axis.text.y = element_text(size = 6),\n",
    "        axis.title.x= element_text(size=6),\n",
    "        plot.title = element_text(size = 6, face = \"bold\"),\n",
    "         legend.title = element_text(size = 6),                         # legend title\n",
    "        legend.text = element_text(size = 6) \n",
    "      )\n",
    "    return(p)\n",
    " })\n",
    "  names(cluster_plots) <- names(sample_results)\n",
    "  return(cluster_plots)\n",
    "})\n",
    "names(plots) <- names(go_results_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "Plot results in playing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(HDF5Array)\n",
    "#saved locally on workstation\n",
    "dir.create(\"Home/Documents/saved_spe_h5\", showWarnings = FALSE)\n",
    "\n",
    "for (sample in names(spe_list_nnsvg[13:22])) {\n",
    "  spe <- spe_list_nnsvg[[sample]]\n",
    "  saveHDF5SummarizedExperiment(\n",
    "    spe,\n",
    "    dir = file.path(\"saved_spe_h5\", paste0(sample, \"_spe_nnsvg_clusterDE\")),\n",
    "    replace = TRUE\n",
    "  )\n",
    "}\n",
    "\n",
    "\n",
    "# Load HVG-filtered RDS files\n",
    "samplesheet <- c(\"SITSA1\", \"SITSA2\", \"SITSA3\", \"SITSA4\",\n",
    "                 \"SITSB1\", \"SITSB2\", \"SITSB3\", \"SITSB4\", \n",
    "                 \"SITSC1\", \"SITSC2\", \"SITSC3\", \"SITSC4\", \n",
    "                 \"SITSD1\", \"SITSD2\", \"SITSD3\", \"SITSD4\",\n",
    "                 \"SITSE2\", \"SITSE4\", \"SITSF2\", \"SITSF4\",\n",
    "                 \"SITSG2\", \"SITSH2\")  \n",
    "                 \n",
    "cluster_files <- list.files(path = \"/home/lythgo02/Documents/saved_spe_h5/\", pattern = \"_spe_nnsvg_clusterDE\", full.names = TRUE)\n",
    "spe_list <- list()\n",
    "names(cluster_files) <- samplesheet\n",
    "\n",
    "for (sample in names(cluster_files)){\n",
    "  spe <- loadHDF5SummarizedExperiment(cluster_files[[sample]])\n",
    "  spe_list[[sample]] <- spe\n",
    "}\n",
    "\n",
    "\n",
    "library(zellkonverter)\n",
    "\n",
    "# Assuming your object is called `spe`\n",
    "\n",
    "for (sample in names(spe_list_nnsvg[1:22])) {\n",
    "  spe <- spe_list_nnsvg[[sample]]\n",
    "  zellkonverter::writeH5AD(\n",
    "    spe,\n",
    "    file = file.path(\"/mnt/scratchc/fmlab/lythgo02/Spatial/saved_spe_h5ad\", paste0(sample, \"_spe_nnsvg_clusterDE.h5ad\"))\n",
    "  )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "Run clustering and GO enrichment within each sample (as you already do).\n",
    "\n",
    "For each subgroup, summarize:\n",
    "    Number of clusters per sample (diversity)\n",
    "    Recurrent GO terms across clusters and samples\n",
    "    Possibly score clusters by significance or similarity\n",
    "    Identify patterns across samples in the same subgroup:\n",
    "    Shared GO terms\n",
    "    Shared cluster structures (e.g., similar cell states)\n",
    "    Variability within/between subgroups\n",
    "\n",
    "Use cluster locations (from colData/colLabels) to compare with image-derived features:\n",
    "    In H&E: align clusters with morphology (e.g., necrosis, ductal regions, stroma).\n",
    "    In mIF: are immune-rich clusters spatially aligned with CD3+, CD8+, or macrophage-rich zones?\n",
    "\n",
    "Advantages:\n",
    "Preserves spatial resolution and biological individuality of each sample.Handles sample heterogeneity well. Identifies dentify subgroup-specific recurrent patterns, not just averages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
